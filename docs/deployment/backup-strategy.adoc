= Backup-Restore strategy
:author: Kyso Inc.
:data-uri:
:doctype: article
:icons: font
:lang: en
ifndef::backend-pdf[:nofooter:] // disable footer except for PDF
:source-highlighter: rouge
:title-page:
:toc: left
:toclevels: 4
// User defined attributes
:sourcedir: ../../..
:docsdir: ..
:includedir: _include
:imagesdir: {docsdir}/images/deployment/backup-strategy

// define 'file_includes' to check it on the included files
:file_includes: true
// Include revnumber.txt (contains a macro with the kitt version number)
include::{docsdir}/revnumber.txt[]

== Overview

This document describes how to backup and restore Kyso from a disaster

== Components involved

The following charts shows the global architecture of Kyso

image::kyso-architecture.png[Kyso Global Architecture]

Not all the components deserves to be considered in a backup strategy, but these are the mandatory ones:

* **MongoDB**. Stores user's data, permissions, organizations, channels, collaboration data (comments, tasks) and report's metadata (title, description, members, authors, etc.). Stores as well the relationship between a report and its files at kyso-scs.
* **kyso-scs**. Stores report's files and folders (including versions of them) and portraits and images (user's portraits, etc.).

And these are the optional ones:
* **Elasticsearch**. Stores the transcripts of the report's files, used for the global search. This data is not critical **because can be re-indexed from the original data stored at kyso-scs**. But could be interesting to backup it if there are huge amounts of data, just to reduce the time-to-recover.

== Strategy

Depending on the needs and the criticality of every customer, the strategy may vary. As a generality, **we recommend to have at least 7 days window of data**.

So, you must configure a set of automatic backups to be executed diary and store the different files related to every backup for at least 7 days.

Take into account that **the data of MongoDB and kyso-scs is related one each other**. So it is interesting to perform the backups ideally when there are no users using the platform. To force this situation, you can uninstall the ingress when the backup is running, and reinstall it when its done, forcing the isolation of the platform during the backup.

Please remember to store the backups in a different infrastructure than Kyso, to avoid the loose of the backups in case of absolute destruction of the infrastructure.

This is the strategy we are following regarding backups:

* **MongoDB**. Dump all the content every day at 03:00am. 7 days window.
* **Kyso-SCS**. Backup the entire pod using velero, every day at 03:00. 7 days window.
* **Elasticsearch**. No backup, reindex if needed.

== Use case using velero

=== Using mongodump and mongorestore

1. Install mongodump and mongorestore

**K**yso's **I**nternal **T**ool of **T**ools, **kitt** for friends, provides you a fast and easy way to do MongoDB backups. Just run the following command:

+
[source,console]
----
$ kitt.sh mongo dump $(date -d "today" +"%Y%m%d%H%M")-mongodb.bck lo
pod/mongo-cli-20230727-185920 created
pod/mongo-cli-20230727-185920 condition met
pod "mongo-cli-20230727-185920" deleted
$ ls -lhrt
-rw-rw-r--  1 user user 158620 jul 27 18:59 202307271859-mongodb.bck
----

+
[NOTE]
======
In the previous example, the last parameter `lo` refers to the CLUSTER_NAME in which the parameter will be executed. If you only have one CLUSTER managed by kitt, you can ignore that parameter.
======

To do it automatically, just create a crontab in unix that executes the previous command. You will need another crontab to delete the old backups, or you can do it manually periodically.


== MongoDB Restore using kitt

To restore a database just run the following command

+
[source,console]
----
$ kitt.sh mongo restore 202307271859-mongodb.bck lo
pod/mongo-cli-20230802-124606 created
pod/mongo-cli-20230802-124606 condition met
2023-08-02T10:46:08.300+0000	preparing collections to restore from
...
2023-08-02T10:46:12.465+0000	129981 document(s) restored successfully. 0 document(s) failed to restore.
pod "mongo-cli-20230802-124606" deleted
----

+
[NOTE]
======
In the previous example, the last parameter `lo` refers to the CLUSTER_NAME in which the parameter will be executed. If you only have one CLUSTER managed by kitt, you can ignore that parameter.
======

== MongoDB and kyso-scs backup using velero

There is another alternative to backup MongoDB, using velero. For that, https://velero.io/docs/v1.11/basic-install/[first follow the official installation instructions].

Velero backups can be stored in different providers, but in this example we are going to store them in an Amazon S3 Bucket. For that, please https://velero.io/docs/v1.0.0/aws-config/[follow the official Velero + AWS instructions]

Once you have the S3 bucket and the account properly configured, it's time to install Velero in your Kubernetes cluster. We are going to use **helm** to install it in our cluster. Create a file named `values.yaml` and put the following values (https://github.com/vmware-tanzu/helm-charts/blob/main/charts/velero/values.yaml[the official documentation is here]):

+
[source,yaml]
----
initContainers:
  - name: velero-plugin-for-aws
    image: velero/velero-plugin-for-aws:v1.4.1
    imagePullPolicy: IfNotPresent
    volumeMounts:
      - mountPath: /target
        name: plugins
configuration:
  provider: aws
  backupStorageLocation:
    name: "aws"
    provider: "velero.io/aws"
    bucket: BUCKET_NAME    # Replace with bucket name you created above
    default: true
    config:
      region: AWS_REGION    # Region where your bucket is located
  volumeSnapshotLocation:
    name: aws
    provider: velero.io/aws
    config:
      region: AWS_REGION    # Region where your volume(s) are located
serviceAccount: 
  server:
    create: true
    name: velero
    annotations: 
      eks.amazonaws.com/role-arn: IAM_ROLE_ARN    # ARN of IAM role created above
schedules: 
  eks-cluster:
    disabled: false
    schedule: "0 0 * * *"  # CRON expression to periodically take backups
    template:
      ttl: "240h"  # This setting will delete backups automatically after 10 days
----

+
[NOTE]
======
Remember to adjust the configuration to your needs
======

Add the helm repository

+
[source,console]
----
$ helm repo add vmware-tanzu https://vmware-tanzu.github.io/helm-charts
----

And install velero

+
[source,console]
----
$ helm install velero vmware-tanzu/velero --namespace <YOUR NAMESPACE> -f values.yaml --create-namespace
----

Now, before starting configuring the automatic backups, let's make a quick test to ensure that velero is working. For that we are going to make a manual backup of all our kubernetes cluster

+
[source,console]
----
$ velero backup create demo
Backup request "demo" submitted successfully.
Run `velero backup describe demo` or `velero backup logs demo` for more details.
----

Confirm that your S3 bucket has a new artifact named `demo`

If everything is ok, it's time to configure automatic backups using velero, and select which components on the architecture you want to backup.

Velero has `schedule` command to program automatic backups. This is the configuration we have in production:

+
[source,console]
----
$ velero schedule get
NAME           STATUS    CREATED                          SCHEDULE     BACKUP TTL   LAST BACKUP   SELECTOR
mongodb-dev    Enabled   2022-06-14 22:00:51 +0200 CEST   30 0 * * *   720h0m0s     10h ago       <none>
kyso-scs-dev   Enabled   2022-06-14 22:01:00 +0200 CEST   45 0 * * *   720h0m0s     10h ago       <none>
----

To create a schedule, just follow Velero's documentation, some examples:

+
[source,console]
----
# Create a backup every 6 hours.
velero create schedule NAME --schedule="0 */6 * * *"

# Create a backup every 6 hours with the @every notation.
velero create schedule NAME --schedule="@every 6h"

# Create a daily backup of the web namespace.
velero create schedule NAME --schedule="@every 24h" --include-namespaces web

# Create a weekly backup, each living for 90 days (2160 hours).
velero create schedule NAME --schedule="@every 168h" --ttl 2160h0m0s
----

Our schedule configurations are:

* For mongodb
+
[source, console]
----
velero schedule describe mongodb-dev
Name:         mongodb-dev
Namespace:    velero
Labels:       <none>
Annotations:  <none>

Phase:  Enabled

Schedule:  30 0 * * *

Backup Template:
  Namespaces:
    Included:  mongodb-dev
    Excluded:  <none>
  
  Resources:
    Included:        *
    Excluded:        <none>
    Cluster-scoped:  auto
  
  Label selector:  <none>
  
  Storage Location:  
  
  Velero-Native Snapshot PVs:  auto
  
  TTL:  720h0m0s
  
  Hooks:  <none>

Last Backup:  2023-08-02 02:30:52 +0200 CEST
----

* For kyso-scs

+
[source, console]
----
velero schedule describe kyso-scs-dev
Name:         kyso-scs-dev
Namespace:    velero
Labels:       <none>
Annotations:  <none>

Phase:  Enabled

Schedule:  45 0 * * *

Backup Template:
  Namespaces:
    Included:  kyso-scs-dev
    Excluded:  <none>
  
  Resources:
    Included:        *
    Excluded:        <none>
    Cluster-scoped:  auto
  
  Label selector:  <none>
  
  Storage Location:  
  
  Velero-Native Snapshot PVs:  auto
  
  TTL:  720h0m0s
  
  Hooks:  <none>

Last Backup:  2023-08-02 02:45:52 +0200 CEST
----

To **restore** a backup, first list the available backups using:

+
[source, console]
----
$ velero backup get
NAME                          STATUS      ERRORS   WARNINGS   CREATED                          EXPIRES   STORAGE LOCATION   SELECTOR
kyso-scs-dev-20230802004552   Completed   0        0          2023-08-02 02:45:52 +0200 CEST   29d       default            <none>
...
kyso-scs-dev-20230704004553   Completed   0        0          2023-07-04 02:45:53 +0200 CEST   13h       default            <none>
mongodb-dev-20230802003052    Completed   0        0          2023-08-02 02:30:52 +0200 CEST   29d       default            <none>
...
mongodb-dev-20230704003053    Completed   0        0          2023-07-04 02:30:53 +0200 CEST   13h       default            <none>
----

Select the backup you want to restore, for example `mongodb-dev-20230704003053` in this case, and launch the next restore command

+
[source, console]
----
$ velero restore create my-restore-name --from-backup mongodb-dev-20230704003053
----

== Elasticsearch reindex

After a restore, it's recommended to perfom a full elasticsearch reindex, to ensure that the indexed data is sync. To do it, you need to have access to a user that is **global administrator** at Kyso, and perform the following commands (which are mostly calls to the API)

. Get a valid auth token (global administrator required)

+
[source, console]
----
$ curl -X 'POST' \
  'https://<your_kyso_server>/api/v1/auth/login' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "password": "n0tiene",
  "provider": "kyso",
  "email": "lo+palpatine@dev.kyso.io"
}'
{"data":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXlsb2FkIjp7ImlkIjoiNjI3MjZmMTdmMmI1MTQyMGI0MzQ5MmI3IiwibGlua3MiOnsic2VsZl9hcGkiOiIiLCJzZWxmX3VpIjoiIn0sIm5hbWUiOiJMb3JkIFBhbHBhdGluZSIsIm5pY2tuYW1lIjoicGFscGF0aW5lIiwidXNlcm5hbWUiOiJwYWxwYXRpbmUiLCJlbWFpbCI6ImxvK3BhbHBhdGluZUBkZXYua3lzby5pbyIsInBsYW4iOiJmcmVlIiwicGVybWlzc2lvbnMiOnsibGlua3MiOnsic2VsZl9hcGkiOiIiLCJzZWxmX3VpIjoiIn0sImdsb2JhbCI6W10sInRlYW1zIjpbXSwib3JnYW5pemF0aW9ucyI6W119LCJhdmF0YXJfdXJsIjpudWxsLCJsb2NhdGlvbiI6IiIsImxpbmsiOiIiLCJiaW8iOiJbUGxhdGZvcm0gQWRtaW5dIFBhbHBhdGluZSBpcyBhIHBsYXRmb3JtIGFkbWluIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsInNob3dfY2FwdGNoYSI6ZmFsc2UsInNob3dfb25ib2FyZGluZyI6ZmFsc2UsImFjY291bnRzIjpbeyJ0eXBlIjoiZ2l0aHViIiwiYWNjb3VudElkIjoiOTg3NDk5MDkiLCJ1c2VybmFtZSI6Im1vemFydG1hZSJ9XX0sImlhdCI6MTY5MDk3NTcyMSwiZXhwIjoxNjkxMDA0NTIxLCJpc3MiOiJreXNvIn0.hJ5g-bHb_pa1d6RYU5dOGvRTsqrSnSwcvMXOpphFFOs","relations":null}
----

. Call the following endpoint using the previously acquired token

+
[source, console]
----
$ curl -X 'GET' \
  'https://dev.kyso.io/api/v1/search/reindex-reports?pathToIndex=/sftp/data/scs' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXlsb2FkIjp7ImlkIjoiNjI3MjZmMTdmMmI1MTQyMGI0MzQ5MmI3IiwibGlua3MiOnsic2VsZl9hcGkiOiIiLCJzZWxmX3VpIjoiIn0sIm5hbWUiOiJMb3JkIFBhbHBhdGluZSIsIm5pY2tuYW1lIjoicGFscGF0aW5lIiwidXNlcm5hbWUiOiJwYWxwYXRpbmUiLCJlbWFpbCI6ImxvK3BhbHBhdGluZUBkZXYua3lzby5pbyIsInBsYW4iOiJmcmVlIiwicGVybWlzc2lvbnMiOnsibGlua3MiOnsic2VsZl9hcGkiOiIiLCJzZWxmX3VpIjoiIn0sImdsb2JhbCI6W10sInRlYW1zIjpbXSwib3JnYW5pemF0aW9ucyI6W119LCJhdmF0YXJfdXJsIjpudWxsLCJsb2NhdGlvbiI6IiIsImxpbmsiOiIiLCJiaW8iOiJbUGxhdGZvcm0gQWRtaW5dIFBhbHBhdGluZSBpcyBhIHBsYXRmb3JtIGFkbWluIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsInNob3dfY2FwdGNoYSI6ZmFsc2UsInNob3dfb25ib2FyZGluZyI6ZmFsc2UsImFjY291bnRzIjpbeyJ0eXBlIjoiZ2l0aHViIiwiYWNjb3VudElkIjoiOTg3NDk5MDkiLCJ1c2VybmFtZSI6Im1vemFydG1hZSJ9XX0sImlhdCI6MTY5MDk3NTcyMSwiZXhwIjoxNjkxMDA0NTIxLCJpc3MiOiJreXNvIn0.hJ5g-bHb_pa1d6RYU5dOGvRTsqrSnSwcvMXOpphFFOs' &
----

The reindex process can last a long time, depending on the data you have stored at Kyso. Please remember that this is an unattended process. If you want to check that the process is running, you can see the kyso-indexer logs using the following command

+
[source, console]
----
$ SCS_CONTAINER=indexer kitt.sh apps kyso-scs logs lo
----

Or the kubectl equivalent

+
[source, console]
----
$ kubectl logs -f --tail=100 -n kyso-scs-lo kyso-scs-0 indexer
--------------------> /kyso-examples/financial-services/quantitative-economics-with-python?path=lectures/_build/html/_static/includes/lecture_howto_py.raw&version=1 upload to elastic returned: 201
Debugger: data
Version 1
Team financial-services
Organization kyso-examples
EntityId 630e276430a4a0c49b8e45bd
----
